## Dataset
The project uses the **RAVDESS** dataset, which consists of 24 actors (12 male and 12 female) performing speech in various emotional states. The dataset contains audio files labeled with emotions such as happy, sad, calm, angry, fearful, etc.

The dataset can be found [here](https://www.kaggle.com/datasets/uw-madison/ravdess-emotional-speech-audio).
